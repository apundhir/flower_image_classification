{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flower Image Classification Parameter optimization with Keras Tuner\n",
    "\n",
    "In this notebook, we will use the Image classification network built in the previous notebook and optimize model Hyperparameters using Keras_tuner library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from skimage import io\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to your dataset\n",
    "DATASET_PATH = './flowers'\n",
    "flowers_cls = ['daisy', 'roses', 'dandelion', 'sunflowers', 'tulips']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare dataset for the model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daisy: 0 Images\n",
      "roses: 0 Images\n",
      "dandelion: 0 Images\n",
      "sunflowers: 0 Images\n",
      "tulips: 0 Images\n"
     ]
    }
   ],
   "source": [
    "for cl in flowers_cls:\n",
    "  imgs_path = os.path.join(DATASET_PATH, cl) #go into dir with name of flower\n",
    "  imgs = glob.glob(imgs_path + '/*.jpg') #find all pics in that dir (pic if ends in jpg)\n",
    "  print(f\"{cl}: {len(imgs)} Images\")\n",
    "  train, val = imgs[:round(len(imgs) * 0.8)], imgs[round(len(imgs) * 0.8):] #80-20 split into train/val datasets\n",
    "\n",
    "  for t in train:\n",
    "    if not os.path.exists(os.path.join(DATASET_PATH, 'train', cl)): #if a path of format flower_photos/train/[class_name] doesn't exist, make one\n",
    "      os.makedirs(os.path.join(DATASET_PATH, 'train', cl)) #use makedirs to create train/[class_name] (mkdir would only create [class_name])\n",
    "    shutil.move(t, os.path.join(DATASET_PATH, 'train', cl))\n",
    "\n",
    "  for v in val:\n",
    "    if not os.path.exists(os.path.join(DATASET_PATH, 'val', cl)): #similar process for validation data\n",
    "      os.makedirs(os.path.join(DATASET_PATH, 'val', cl)) \n",
    "    shutil.move(v, os.path.join(DATASET_PATH, 'val', cl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(DATASET_PATH, 'train')\n",
    "val_dir = os.path.join(DATASET_PATH, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Parameters\n",
    "BATCH_SIZE = 100\n",
    "IMG_SHAPE = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2935 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "## Data Augmentation\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=45,\n",
    "    width_shift_range=.15,\n",
    "    height_shift_range=.15,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.5\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_SHAPE, IMG_SHAPE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 735 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "## Validation Data Generator\n",
    "val_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMG_SHAPE, IMG_SHAPE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img,train_lables = train_generator.next()\n",
    "val_img,val_lables = val_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 150, 150, 3), (100, 5), (100, 150, 150, 3), (100, 5))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img.shape,train_lables.shape,val_img.shape,val_lables.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model from previous notebook\n",
    "\n",
    "# model = Sequential([\n",
    "#     Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_SHAPE, IMG_SHAPE, 3)),\n",
    "#     MaxPooling2D(),\n",
    "#     Conv2D(32, 3, padding='same', activation='relu'),\n",
    "#     MaxPooling2D(),\n",
    "#     Conv2D(64, 3, padding='same', activation='relu'),\n",
    "#     MaxPooling2D(),\n",
    "#     Flatten(),\n",
    "#     Dropout(0.2),\n",
    "#     Dense(512, activation='relu'),\n",
    "#     Dropout(0.2),\n",
    "#     Dense(5, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# model.compile(optimizer='adam',\n",
    "#                 loss='categorical_crossentropy',\n",
    "#                 metrics=['accuracy'])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "  model = keras.Sequential()\n",
    "  # Convolution Layers\n",
    "  model.add(keras.layers.Conv2D(filters=hp.Int(\"conv_1\", min_value=64, max_value=128, step=32),\n",
    "                                              kernel_size=hp.Choice('conv_1_kernel', values = [3,5]), \n",
    "                                              padding='same', \n",
    "                                              activation='relu', \n",
    "                                              input_shape=(IMG_SHAPE, IMG_SHAPE, 3)))\n",
    "  model.add(keras.layers.Conv2D(filters=hp.Int(\"conv_2\", min_value=32, max_value=64, step=16),\n",
    "                                              kernel_size=hp.Choice('conv_2_kernel', values = [3,5]), \n",
    "                                              padding='same', \n",
    "                                              activation='relu', \n",
    "                                              input_shape=(IMG_SHAPE, IMG_SHAPE, 3)))\n",
    "  # Batch Normalization Layer\n",
    "  model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "  # Pooling Layer\n",
    "  model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "  # Flatten Layer\n",
    "  model.add(keras.layers.Flatten())\n",
    "  model.add(keras.layers.Dense(units=hp.Int('units', min_value=32, max_value=512, step=32), activation='relu'))\n",
    "  model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "  # Dropout Layer\n",
    "  model.add(keras.layers.Dropout(rate=hp.Float('dropout_1', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "\n",
    "  # Output Layer\n",
    "  # The parameter is set to 5 because we have 5 different classes of flowers\n",
    "  # Softmax is used to convert the output to a probability distribution\n",
    "  # The class with the highest probability is the models prediction\n",
    "  # For example, [0.1, 0.1, 0.1, 0.6, 0.1] means the model predicts the image is a tulip\n",
    "  model.add(keras.layers.Dense(5, activation='softmax'))\n",
    "\n",
    "  # Tune the learning rate for the optimizer\n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from my_dir/intro_to_kt/tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from my_dir/intro_to_kt/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=100,\n",
    "                     factor=3,\n",
    "                     seed=42,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, min_delta=0.02, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 512 and the optimal learning rate for the optimizer\n",
      "is 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner.search(train_img, train_lables, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 2s 501ms/step - loss: 5.1624 - accuracy: 0.1500 - val_loss: 7.0134 - val_accuracy: 0.1500\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 1s 439ms/step - loss: 1.4147 - accuracy: 0.6125 - val_loss: 3.0165 - val_accuracy: 0.1500\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 1s 446ms/step - loss: 0.5850 - accuracy: 0.8000 - val_loss: 2.2067 - val_accuracy: 0.2500\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 1s 435ms/step - loss: 0.4083 - accuracy: 0.8875 - val_loss: 2.1071 - val_accuracy: 0.2500\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 1s 443ms/step - loss: 0.2437 - accuracy: 0.9250 - val_loss: 1.8804 - val_accuracy: 0.2500\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 1s 438ms/step - loss: 0.0996 - accuracy: 0.9750 - val_loss: 1.9148 - val_accuracy: 0.2000\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 1s 439ms/step - loss: 0.0810 - accuracy: 0.9875 - val_loss: 1.9553 - val_accuracy: 0.2000\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 1s 441ms/step - loss: 0.1079 - accuracy: 0.9750 - val_loss: 1.9070 - val_accuracy: 0.2500\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 1s 444ms/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 1.8418 - val_accuracy: 0.3500\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 1s 445ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 1.7597 - val_accuracy: 0.3500\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 1s 439ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.7071 - val_accuracy: 0.3500\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 1s 463ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 1.6914 - val_accuracy: 0.3500\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 1s 444ms/step - loss: 0.0298 - accuracy: 0.9875 - val_loss: 1.6762 - val_accuracy: 0.4000\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 1s 440ms/step - loss: 0.0387 - accuracy: 0.9875 - val_loss: 1.6058 - val_accuracy: 0.4000\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 1s 441ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.5102 - val_accuracy: 0.4500\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 1s 435ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.4365 - val_accuracy: 0.4500\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 1s 441ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 1.4267 - val_accuracy: 0.4500\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 1s 439ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.4811 - val_accuracy: 0.5000\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 1s 442ms/step - loss: 0.0242 - accuracy: 0.9875 - val_loss: 1.4706 - val_accuracy: 0.4500\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 1s 433ms/step - loss: 0.0373 - accuracy: 0.9875 - val_loss: 1.4945 - val_accuracy: 0.4500\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 1s 442ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.6567 - val_accuracy: 0.2000\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 1s 438ms/step - loss: 0.0207 - accuracy: 0.9875 - val_loss: 1.8091 - val_accuracy: 0.2000\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 1s 439ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 1.7242 - val_accuracy: 0.2000\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 1s 444ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.5866 - val_accuracy: 0.2500\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 1s 440ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 1.4877 - val_accuracy: 0.4000\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 1s 437ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.4218 - val_accuracy: 0.4500\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 1s 444ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.4050 - val_accuracy: 0.4500\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 1s 438ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.4250 - val_accuracy: 0.4500\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 1s 438ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.4297 - val_accuracy: 0.4500\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 1s 433ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.4384 - val_accuracy: 0.4500\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 1s 436ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.4332 - val_accuracy: 0.4500\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 1s 444ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.4259 - val_accuracy: 0.4500\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 1s 440ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.4178 - val_accuracy: 0.4000\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 1s 437ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.3898 - val_accuracy: 0.4500\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 1s 441ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.3568 - val_accuracy: 0.4500\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 1s 449ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.3401 - val_accuracy: 0.4500\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 1s 436ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.3244 - val_accuracy: 0.4500\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 1s 442ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3126 - val_accuracy: 0.4500\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 1s 441ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3049 - val_accuracy: 0.4500\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 1s 442ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2978 - val_accuracy: 0.4500\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 1s 442ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.2910 - val_accuracy: 0.4500\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 1s 440ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2863 - val_accuracy: 0.4500\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 1s 440ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2798 - val_accuracy: 0.5000\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 1s 441ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.2790 - val_accuracy: 0.5000\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 1s 437ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2834 - val_accuracy: 0.5000\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 1s 441ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.2848 - val_accuracy: 0.5000\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 1s 439ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.2904 - val_accuracy: 0.5000\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 1s 440ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2960 - val_accuracy: 0.5000\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 1s 434ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2979 - val_accuracy: 0.5000\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 1s 434ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.2958 - val_accuracy: 0.5000\n",
      "Best epoch: 18\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(train_img, train_lables, epochs=50, validation_split=0.2)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "3/3 [==============================] - 2s 480ms/step - loss: 5.1094 - accuracy: 0.3625 - val_loss: 6.4467 - val_accuracy: 0.2000\n",
      "Epoch 2/18\n",
      "3/3 [==============================] - 1s 445ms/step - loss: 2.6814 - accuracy: 0.4625 - val_loss: 2.1317 - val_accuracy: 0.4000\n",
      "Epoch 3/18\n",
      "3/3 [==============================] - 1s 442ms/step - loss: 1.4762 - accuracy: 0.6750 - val_loss: 1.2480 - val_accuracy: 0.6000\n",
      "Epoch 4/18\n",
      "3/3 [==============================] - 1s 441ms/step - loss: 0.7003 - accuracy: 0.7500 - val_loss: 1.2817 - val_accuracy: 0.5000\n",
      "Epoch 5/18\n",
      "3/3 [==============================] - 1s 439ms/step - loss: 0.5878 - accuracy: 0.8000 - val_loss: 1.5092 - val_accuracy: 0.3000\n",
      "Epoch 6/18\n",
      "3/3 [==============================] - 1s 439ms/step - loss: 0.2601 - accuracy: 0.9250 - val_loss: 1.3550 - val_accuracy: 0.2500\n",
      "Epoch 7/18\n",
      "3/3 [==============================] - 1s 442ms/step - loss: 0.1442 - accuracy: 0.9625 - val_loss: 1.3304 - val_accuracy: 0.4500\n",
      "Epoch 8/18\n",
      "3/3 [==============================] - 1s 454ms/step - loss: 0.1341 - accuracy: 0.9500 - val_loss: 1.5743 - val_accuracy: 0.3500\n",
      "Epoch 9/18\n",
      "3/3 [==============================] - 1s 448ms/step - loss: 0.1299 - accuracy: 0.9750 - val_loss: 1.6659 - val_accuracy: 0.3500\n",
      "Epoch 10/18\n",
      "3/3 [==============================] - 1s 447ms/step - loss: 0.0626 - accuracy: 0.9875 - val_loss: 1.6004 - val_accuracy: 0.3500\n",
      "Epoch 11/18\n",
      "3/3 [==============================] - 1s 449ms/step - loss: 0.0609 - accuracy: 0.9750 - val_loss: 1.3210 - val_accuracy: 0.5500\n",
      "Epoch 12/18\n",
      "3/3 [==============================] - 1s 443ms/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 1.3445 - val_accuracy: 0.4000\n",
      "Epoch 13/18\n",
      "3/3 [==============================] - 1s 438ms/step - loss: 0.0377 - accuracy: 1.0000 - val_loss: 1.3635 - val_accuracy: 0.4000\n",
      "Epoch 14/18\n",
      "3/3 [==============================] - 1s 436ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 1.3548 - val_accuracy: 0.3500\n",
      "Epoch 15/18\n",
      "3/3 [==============================] - 1s 445ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 1.3132 - val_accuracy: 0.3500\n",
      "Epoch 16/18\n",
      "3/3 [==============================] - 1s 441ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 1.2680 - val_accuracy: 0.3500\n",
      "Epoch 17/18\n",
      "3/3 [==============================] - 1s 436ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 1.2161 - val_accuracy: 0.5000\n",
      "Epoch 18/18\n",
      "3/3 [==============================] - 1s 448ms/step - loss: 0.0836 - accuracy: 0.9875 - val_loss: 1.1794 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bf33df90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "hypermodel.fit(train_img, train_lables, epochs=best_epoch, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 101ms/step - loss: 1.4840 - accuracy: 0.3400\n",
      "[test loss, test accuracy]: [1.4840492010116577, 0.3400000035762787]\n"
     ]
    }
   ],
   "source": [
    "eval_result = hypermodel.evaluate(val_img, val_lables)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
